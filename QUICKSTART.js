#!/usr/bin/env node

/**
 * Quick Start Guide
 * Shows all available commands and how to use them
 */

const COLORS = {
  reset: '\x1b[0m',
  bright: '\x1b[1m',
  green: '\x1b[32m',
  yellow: '\x1b[33m',
  blue: '\x1b[34m',
  cyan: '\x1b[36m',
};

function log(message, color = 'reset') {
  console.log(`${COLORS[color]}${message}${COLORS.reset}`);
}

log('\n', 'bright');
log('â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—', 'cyan');
log('â•‘                                                                        â•‘', 'cyan');
log('â•‘           ğŸš€ UNIVERSAL AI GATEWAY - QUICK START GUIDE ğŸš€             â•‘', 'cyan');
log('â•‘                                                                        â•‘', 'cyan');
log('â•‘              One API for all AI services (Gemini, OpenAI, etc.)      â•‘', 'cyan');
log('â•‘                                                                        â•‘', 'cyan');
log('â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•', 'cyan');

log('\nğŸ“‹ SETUP', 'bright');
log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');

log('\n1ï¸âƒ£  Install Dependencies:', 'blue');
log('   npm install', 'green');

log('\n2ï¸âƒ£  Configure Environment:', 'blue');
log('   cp .env.example .env', 'green');
log('   Edit .env and add your API keys', 'yellow');

log('\n\nğŸ”‘ REQUIRED API KEYS', 'bright');
log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');

const providers = [
  { name: 'Gemini (Google)', url: 'https://ai.google.dev', free: 'âœ…' },
  { name: 'OpenAI (ChatGPT)', url: 'https://platform.openai.com', free: 'ğŸ’°' },
  { name: 'Claude (Anthropic)', url: 'https://console.anthropic.com', free: 'ğŸ’°' },
  { name: 'Groq', url: 'https://console.groq.com', free: 'âœ…' },
  { name: 'HuggingFace', url: 'https://huggingface.co/settings/tokens', free: 'âœ…' },
  { name: 'Ollama (Local)', url: 'https://ollama.ai', free: 'âœ…' },
];

providers.forEach(p => {
  log(`\n${p.free} ${p.name}`, 'yellow');
  log(`   ${p.url}`, 'cyan');
});

log('\n\nğŸš€ RUN LOCALLY', 'bright');
log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');

log('\nOption A: Docker (Recommended)', 'blue');
log('   docker-compose -f docker/docker-compose.yml up -d', 'green');
log('   Gateway: http://localhost:3000', 'cyan');
log('   Open WebUI: http://localhost:3001', 'cyan');

log('\nOption B: Manual', 'blue');
log('   npm run dev', 'green');
log('   http://localhost:3000', 'cyan');

log('\n\nğŸ’» USAGE EXAMPLES', 'bright');
log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');

log('\nğŸ Python:', 'blue');
log(`   from clients.ai_gateway_client import AIGatewayClient
   client = AIGatewayClient('http://localhost:3000')
   response = client.chat('gemini', 'Hello!')
   print(response['message'])`, 'green');

log('\nğŸ”— JavaScript:', 'blue');
log(`   const AIGatewayClient = require('./clients/AIGatewayClient');
   const client = new AIGatewayClient('http://localhost:3000');
   const response = await client.chat('gemini', 'Hello!');
   console.log(response.message);`, 'green');

log('\nğŸ“¡ cURL:', 'blue');
log(`   curl -X POST http://localhost:3000/api/chat \\
     -H "Content-Type: application/json" \\
     -d '{"provider":"gemini","message":"Hello!"}'`, 'green');

log('\n\nğŸŒ ENDPOINTS', 'bright');
log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');

log('\nPOST /api/chat', 'blue');
log('   Send message to any provider');

log('\nGET /api/models?provider=gemini', 'blue');
log('   List available models');

log('\nGET /api/health', 'blue');
log('   Check gateway health');

log('\n\nâš¡ PROVIDERS SUPPORTED', 'bright');
log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');

log('\nâœ… Gemini (gemini-1.5-pro) - FREE', 'green');
log('âœ… Groq (mixtral-8x7b-32768) - FREE & FAST', 'green');
log('âœ… Ollama (mistral) - FREE & LOCAL', 'green');
log('ğŸ’° OpenAI (gpt-4-turbo) - PAID', 'yellow');
log('ğŸ’° Claude (claude-3-opus) - PAID', 'yellow');
log('âœ… HuggingFace (Llama-2) - FREE', 'green');

log('\n\nğŸ“¦ DEPLOY TO VERCEL', 'bright');
log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');

log('\nAutomatic (recommended):', 'blue');
log('   node deploy.js', 'green');
log('   (Pushes to GitHub & deploys to Vercel)', 'cyan');

log('\nManual:', 'blue');
log('   1. Push to GitHub: git push origin main', 'green');
log('   2. Connect at https://vercel.com/dashboard', 'green');
log('   3. Add environment variables', 'green');
log('   4. Deploy!', 'green');

log('\n\nğŸ“š DOCUMENTATION', 'bright');
log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');

log('\nğŸ“– Full README:', 'blue');
log('   cat README.md', 'green');

log('\nğŸ³ Docker setup:', 'blue');
log('   docker/docker-compose.yml', 'green');

log('\nğŸ Python client:', 'blue');
log('   clients/ai_gateway_client.py', 'green');

log('\nğŸ”— JavaScript client:', 'blue');
log('   clients/AIGatewayClient.js', 'green');

log('\n\nğŸ†˜ TROUBLESHOOTING', 'bright');
log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');

log('\nâŒ "Cannot connect to gateway"', 'red');
log('   âœ… Is the gateway running? (npm run dev or docker-compose up)', 'green');
log('   âœ… Check PORT 3000 is not in use', 'green');

log('\nâŒ "Provider not configured"', 'red');
log('   âœ… Add API key to .env', 'green');
log('   âœ… Restart gateway', 'green');

log('\nâŒ "Ollama connection error"', 'red');
log('   âœ… Is Ollama running? (docker-compose up)', 'green');
log('   âœ… Check OLLAMA_URL in .env', 'green');

log('\n\nâœ¨ YOU\'RE ALL SET!', 'bright');
log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');

log('\nğŸ¯ Next steps:', 'cyan');
log('   1. npm install', 'yellow');
log('   2. cp .env.example .env (add your API keys)', 'yellow');
log('   3. npm run dev (or docker-compose up)', 'yellow');
log('   4. Visit http://localhost:3000/api/health', 'yellow');
log('   5. Start using the gateway! ğŸš€', 'yellow');

log('\nğŸ’¡ Pro tips:', 'cyan');
log('   â€¢ Use Gemini or Groq for FREE unlimited usage', 'yellow');
log('   â€¢ Use Ollama for completely LOCAL models (no API key needed)', 'yellow');
log('   â€¢ Mix providers for the best results', 'yellow');

log('\nğŸ“ Need help?', 'cyan');
log('   GitHub: https://github.com/NeXifiyAI/ai-gateway', 'blue');
log('   Issues: https://github.com/NeXifiyAI/ai-gateway/issues', 'blue');

log('\n\n');
